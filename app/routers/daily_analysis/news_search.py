"""
æ–°é—»æœç´¢æœåŠ¡æ¨¡å—

é›†æˆè‡ª daily_stock_analysis é¡¹ç›®ï¼Œæ”¯æŒï¼š
- Bocha (åšæŸ¥) - ä¼˜å…ˆä½¿ç”¨ï¼Œä¸­æ–‡æœç´¢ä¼˜åŒ–
- Tavily - æ¯æœˆ1000æ¬¡å…è´¹
- SerpAPI - å¤‡é€‰æ–¹æ¡ˆ
"""

import logging
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from itertools import cycle

logger = logging.getLogger(__name__)


@dataclass
class NewsResult:
    """å•æ¡æ–°é—»ç»“æœ"""
    title: str
    snippet: str
    url: str
    source: str
    published_date: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "title": self.title,
            "snippet": self.snippet,
            "url": self.url,
            "source": self.source,
            "published_date": self.published_date
        }


@dataclass
class NewsResponse:
    """æ–°é—»æœç´¢å“åº”"""
    query: str
    results: List[NewsResult]
    provider: str
    success: bool = True
    error_message: Optional[str] = None
    search_time: float = 0.0

    def to_context(self, max_results: int = 5) -> str:
        """è½¬æ¢ä¸ºç”¨äº AI åˆ†æçš„ä¸Šä¸‹æ–‡æ–‡æœ¬"""
        if not self.success or not self.results:
            return f"æœç´¢ '{self.query}' æœªæ‰¾åˆ°ç›¸å…³ç»“æœã€‚"

        lines = [f"ã€{self.query} æœç´¢ç»“æœã€‘ï¼ˆæ¥æºï¼š{self.provider}ï¼‰"]
        for i, result in enumerate(self.results[:max_results], 1):
            date_str = f" ({result.published_date})" if result.published_date else ""
            lines.append(f"\n{i}. ã€{result.source}ã€‘{result.title}{date_str}")
            lines.append(f"   {result.snippet[:200]}...")

        return "\n".join(lines)


class BaseSearchProvider(ABC):
    """æœç´¢å¼•æ“åŸºç±»"""

    def __init__(self, api_keys: List[str], name: str):
        self._api_keys = api_keys
        self._name = name
        self._key_cycle = cycle(api_keys) if api_keys else None
        self._key_errors: Dict[str, int] = {key: 0 for key in api_keys}

    @property
    def name(self) -> str:
        return self._name

    @property
    def is_available(self) -> bool:
        return bool(self._api_keys)

    def _get_next_key(self) -> Optional[str]:
        if not self._key_cycle:
            return None

        for _ in range(len(self._api_keys)):
            key = next(self._key_cycle)
            if self._key_errors.get(key, 0) < 3:
                return key

        logger.warning(f"[{self._name}] æ‰€æœ‰ API Key éƒ½æœ‰é”™è¯¯è®°å½•ï¼Œé‡ç½®")
        self._key_errors = {key: 0 for key in self._api_keys}
        return self._api_keys[0] if self._api_keys else None

    def _record_success(self, key: str) -> None:
        if key in self._key_errors and self._key_errors[key] > 0:
            self._key_errors[key] -= 1

    def _record_error(self, key: str) -> None:
        self._key_errors[key] = self._key_errors.get(key, 0) + 1
        logger.warning(f"[{self._name}] API Key é”™è¯¯è®¡æ•°: {self._key_errors[key]}")

    @abstractmethod
    def _do_search(self, query: str, api_key: str, max_results: int) -> NewsResponse:
        pass

    def search(self, query: str, max_results: int = 5) -> NewsResponse:
        api_key = self._get_next_key()
        if not api_key:
            return NewsResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=f"{self._name} æœªé…ç½® API Key"
            )

        start_time = time.time()
        try:
            response = self._do_search(query, api_key, max_results)
            response.search_time = time.time() - start_time

            if response.success:
                self._record_success(api_key)
                logger.info(f"[{self._name}] æœç´¢æˆåŠŸï¼Œè¿”å› {len(response.results)} æ¡")
            else:
                self._record_error(api_key)

            return response

        except Exception as e:
            self._record_error(api_key)
            elapsed = time.time() - start_time
            logger.error(f"[{self._name}] æœç´¢å¤±è´¥: {e}")
            return NewsResponse(
                query=query,
                results=[],
                provider=self._name,
                success=False,
                error_message=str(e),
                search_time=elapsed
            )


class BochaSearchProvider(BaseSearchProvider):
    """
    åšæŸ¥æœç´¢å¼•æ“
    ä¸“ä¸º AI ä¼˜åŒ–çš„ä¸­æ–‡æœç´¢ API
    """

    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Bocha")

    def _do_search(self, query: str, api_key: str, max_results: int) -> NewsResponse:
        try:
            import requests
        except ImportError:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="requests æœªå®‰è£…"
            )

        try:
            url = "https://api.bocha.cn/v1/web-search"
            headers = {
                'Authorization': f'Bearer {api_key}',
                'Content-Type': 'application/json'
            }
            payload = {
                "query": query,
                "freshness": "oneMonth",
                "summary": True,
                "count": min(max_results, 50)
            }

            response = requests.post(url, headers=headers, json=payload, timeout=10)

            if response.status_code != 200:
                error_msg = response.text
                if response.status_code == 403:
                    error_msg = f"ä½™é¢ä¸è¶³: {error_msg}"
                elif response.status_code == 401:
                    error_msg = f"API KEYæ— æ•ˆ: {error_msg}"

                return NewsResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=error_msg
                )

            data = response.json()

            if data.get('code') != 200:
                return NewsResponse(
                    query=query,
                    results=[],
                    provider=self.name,
                    success=False,
                    error_message=data.get('msg', 'APIè¿”å›é”™è¯¯')
                )

            results = []
            web_pages = data.get('data', {}).get('webPages', {})
            for item in web_pages.get('value', [])[:max_results]:
                snippet = item.get('summary') or item.get('snippet', '')
                if snippet:
                    snippet = snippet[:500]

                results.append(NewsResult(
                    title=item.get('name', ''),
                    snippet=snippet,
                    url=item.get('url', ''),
                    source=item.get('siteName', ''),
                    published_date=item.get('datePublished')
                ))

            return NewsResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )

        except requests.exceptions.Timeout:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="è¯·æ±‚è¶…æ—¶"
            )
        except Exception as e:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=str(e)
            )


class TavilySearchProvider(BaseSearchProvider):
    """Tavily æœç´¢å¼•æ“"""

    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "Tavily")

    def _do_search(self, query: str, api_key: str, max_results: int) -> NewsResponse:
        try:
            from tavily import TavilyClient
        except ImportError:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="tavily-python æœªå®‰è£…"
            )

        try:
            client = TavilyClient(api_key=api_key)
            response = client.search(
                query=query,
                search_depth="advanced",
                max_results=max_results,
                include_answer=False,
                include_raw_content=False,
                days=7,
            )

            results = []
            for item in response.get('results', []):
                results.append(NewsResult(
                    title=item.get('title', ''),
                    snippet=item.get('content', '')[:500],
                    url=item.get('url', ''),
                    source=self._extract_domain(item.get('url', '')),
                    published_date=item.get('published_date'),
                ))

            return NewsResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )

        except Exception as e:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=str(e)
            )

    @staticmethod
    def _extract_domain(url: str) -> str:
        try:
            from urllib.parse import urlparse
            parsed = urlparse(url)
            return parsed.netloc.replace('www.', '') or 'æœªçŸ¥æ¥æº'
        except:
            return 'æœªçŸ¥æ¥æº'


class SerpAPISearchProvider(BaseSearchProvider):
    """SerpAPI æœç´¢å¼•æ“"""

    def __init__(self, api_keys: List[str]):
        super().__init__(api_keys, "SerpAPI")

    def _do_search(self, query: str, api_key: str, max_results: int) -> NewsResponse:
        try:
            from serpapi import GoogleSearch
        except ImportError:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message="google-search-results æœªå®‰è£…"
            )

        try:
            params = {
                "engine": "baidu",
                "q": query,
                "api_key": api_key,
            }

            search = GoogleSearch(params)
            response = search.get_dict()

            results = []
            for item in response.get('organic_results', [])[:max_results]:
                results.append(NewsResult(
                    title=item.get('title', ''),
                    snippet=item.get('snippet', '')[:500],
                    url=item.get('link', ''),
                    source=item.get('source', ''),
                    published_date=item.get('date'),
                ))

            return NewsResponse(
                query=query,
                results=results,
                provider=self.name,
                success=True,
            )

        except Exception as e:
            return NewsResponse(
                query=query,
                results=[],
                provider=self.name,
                success=False,
                error_message=str(e)
            )


class NewsSearchService:
    """
    æ–°é—»æœç´¢æœåŠ¡

    ç®¡ç†å¤šä¸ªæœç´¢å¼•æ“ï¼Œè‡ªåŠ¨æ•…éšœè½¬ç§»
    """

    def __init__(
        self,
        bocha_keys: Optional[List[str]] = None,
        tavily_keys: Optional[List[str]] = None,
        serpapi_keys: Optional[List[str]] = None,
    ):
        self._providers: List[BaseSearchProvider] = []

        # æŒ‰ä¼˜å…ˆçº§åˆå§‹åŒ–æœç´¢å¼•æ“
        if bocha_keys:
            self._providers.append(BochaSearchProvider(bocha_keys))
            logger.info(f"å·²é…ç½® Bocha æœç´¢ï¼Œå…± {len(bocha_keys)} ä¸ª API Key")

        if tavily_keys:
            self._providers.append(TavilySearchProvider(tavily_keys))
            logger.info(f"å·²é…ç½® Tavily æœç´¢ï¼Œå…± {len(tavily_keys)} ä¸ª API Key")

        if serpapi_keys:
            self._providers.append(SerpAPISearchProvider(serpapi_keys))
            logger.info(f"å·²é…ç½® SerpAPI æœç´¢ï¼Œå…± {len(serpapi_keys)} ä¸ª API Key")

        if not self._providers:
            logger.warning("æœªé…ç½®ä»»ä½•æœç´¢å¼•æ“ API Key")

    @property
    def is_available(self) -> bool:
        return any(p.is_available for p in self._providers)

    def search_stock_news(
        self,
        stock_code: str,
        stock_name: str,
        max_results: int = 5
    ) -> NewsResponse:
        """
        æœç´¢è‚¡ç¥¨ç›¸å…³æ–°é—»

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_results: æœ€å¤§è¿”å›ç»“æœæ•°

        Returns:
            NewsResponse å¯¹è±¡
        """
        query = f"{stock_name} {stock_code} è‚¡ç¥¨ æœ€æ–°æ¶ˆæ¯"

        logger.info(f"æœç´¢è‚¡ç¥¨æ–°é—»: {stock_name}({stock_code})")

        for provider in self._providers:
            if not provider.is_available:
                continue

            response = provider.search(query, max_results)

            if response.success and response.results:
                logger.info(f"ä½¿ç”¨ {provider.name} æœç´¢æˆåŠŸ")
                return response

        return NewsResponse(
            query=query,
            results=[],
            provider="None",
            success=False,
            error_message="æ‰€æœ‰æœç´¢å¼•æ“éƒ½ä¸å¯ç”¨æˆ–æœç´¢å¤±è´¥"
        )

    def search_comprehensive_intel(
        self,
        stock_code: str,
        stock_name: str,
        max_searches: int = 3
    ) -> Dict[str, NewsResponse]:
        """
        å¤šç»´åº¦æƒ…æŠ¥æœç´¢

        æœç´¢ç»´åº¦ï¼š
        1. æœ€æ–°æ¶ˆæ¯ - è¿‘æœŸæ–°é—»åŠ¨æ€
        2. é£é™©æ’æŸ¥ - å‡æŒã€å¤„ç½šã€åˆ©ç©º
        3. ä¸šç»©é¢„æœŸ - å¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥

        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            stock_name: è‚¡ç¥¨åç§°
            max_searches: æœ€å¤§æœç´¢æ¬¡æ•°

        Returns:
            {ç»´åº¦åç§°: NewsResponse} å­—å…¸
        """
        results = {}
        search_count = 0

        search_dimensions = [
            {
                'name': 'latest_news',
                'query': f"{stock_name} {stock_code} æœ€æ–° æ–°é—»",
                'desc': 'æœ€æ–°æ¶ˆæ¯'
            },
            {
                'name': 'risk_check',
                'query': f"{stock_name} å‡æŒ å¤„ç½š åˆ©ç©º é£é™©",
                'desc': 'é£é™©æ’æŸ¥'
            },
            {
                'name': 'earnings',
                'query': f"{stock_name} å¹´æŠ¥é¢„å‘Š ä¸šç»©é¢„å‘Š ä¸šç»©å¿«æŠ¥",
                'desc': 'ä¸šç»©é¢„æœŸ'
            },
        ]

        logger.info(f"å¼€å§‹å¤šç»´åº¦æƒ…æŠ¥æœç´¢: {stock_name}({stock_code})")

        provider_index = 0
        available_providers = [p for p in self._providers if p.is_available]

        for dim in search_dimensions:
            if search_count >= max_searches or not available_providers:
                break

            provider = available_providers[provider_index % len(available_providers)]
            provider_index += 1

            logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: ä½¿ç”¨ {provider.name}")

            response = provider.search(dim['query'], max_results=3)
            results[dim['name']] = response
            search_count += 1

            if response.success:
                logger.info(f"[æƒ…æŠ¥æœç´¢] {dim['desc']}: è·å– {len(response.results)} æ¡ç»“æœ")

            time.sleep(0.5)

        return results

    def format_intel_report(self, intel_results: Dict[str, NewsResponse], stock_name: str) -> str:
        """æ ¼å¼åŒ–æƒ…æŠ¥æœç´¢ç»“æœä¸ºæŠ¥å‘Š"""
        lines = [f"ã€{stock_name} æƒ…æŠ¥æœç´¢ç»“æœã€‘"]

        if 'latest_news' in intel_results:
            resp = intel_results['latest_news']
            lines.append(f"\nğŸ“° æœ€æ–°æ¶ˆæ¯ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    date_str = f" [{r.published_date}]" if r.published_date else ""
                    lines.append(f"  {i}. {r.title}{date_str}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ç›¸å…³æ¶ˆæ¯")

        if 'risk_check' in intel_results:
            resp = intel_results['risk_check']
            lines.append(f"\nâš ï¸ é£é™©æ’æŸ¥ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    lines.append(f"  {i}. {r.title}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªå‘ç°æ˜æ˜¾é£é™©ä¿¡å·")

        if 'earnings' in intel_results:
            resp = intel_results['earnings']
            lines.append(f"\nğŸ“Š ä¸šç»©é¢„æœŸ (æ¥æº: {resp.provider}):")
            if resp.success and resp.results:
                for i, r in enumerate(resp.results[:3], 1):
                    lines.append(f"  {i}. {r.title}")
                    lines.append(f"     {r.snippet[:100]}...")
            else:
                lines.append("  æœªæ‰¾åˆ°ä¸šç»©ç›¸å…³ä¿¡æ¯")

        return "\n".join(lines)


# å…¨å±€å®ä¾‹
_news_service: Optional[NewsSearchService] = None


def get_news_service() -> NewsSearchService:
    """è·å–æ–°é—»æœç´¢æœåŠ¡å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global _news_service

    if _news_service is None:
        # ä»é…ç½®è¯»å– API Keys
        try:
            from app.core.unified_config import unified_config

            # å°è¯•ä»é…ç½®è·å– API Keys
            # æ³¨æ„ï¼šéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­æ·»åŠ è¿™äº›é…ç½®
            bocha_keys = []
            tavily_keys = []
            serpapi_keys = []

            # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
            import os
            if os.getenv("BOCHA_API_KEY"):
                bocha_keys = [os.getenv("BOCHA_API_KEY")]
            if os.getenv("TAVILY_API_KEY"):
                tavily_keys = [os.getenv("TAVILY_API_KEY")]
            if os.getenv("SERPAPI_KEY"):
                serpapi_keys = [os.getenv("SERPAPI_KEY")]

            _news_service = NewsSearchService(
                bocha_keys=bocha_keys,
                tavily_keys=tavily_keys,
                serpapi_keys=serpapi_keys,
            )

            if _news_service.is_available:
                logger.info("æ–°é—»æœç´¢æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
            else:
                logger.warning("æ–°é—»æœç´¢æœåŠ¡æœªé…ç½® API Key")

        except Exception as e:
            logger.error(f"æ–°é—»æœç´¢æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
            _news_service = NewsSearchService()

    return _news_service


def reset_news_service() -> None:
    """é‡ç½®æ–°é—»æœç´¢æœåŠ¡ï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
    global _news_service
    _news_service = None
