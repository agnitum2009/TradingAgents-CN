"""
ç»Ÿä¸€ç¼“å­˜ç®¡ç†æœåŠ¡

Phase 3-05: Cache Optimization

æä¾›ç»Ÿä¸€çš„ç¼“å­˜é…ç½®ã€ç›‘æ§å’Œç®¡ç†åŠŸèƒ½ï¼š
- åˆ†å±‚ç¼“å­˜ç­–ç•¥ (Redis/Memory/File)
- ç¼“å­˜é¢„çƒ­å’Œå¤±æ•ˆç­–ç•¥
- ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
- è‡ªåŠ¨é™çº§å’Œå®¹é”™
"""

import asyncio
import json
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Union
from functools import wraps
from contextlib import asynccontextmanager

from .redis_client import get_redis_service, RedisService
from .config_cache import ConfigCache

logger = logging.getLogger(__name__)


class CacheLevel(Enum):
    """ç¼“å­˜çº§åˆ«"""
    L1_MEMORY = "l1_memory"      # è¿›ç¨‹å†…å†…å­˜ç¼“å­˜ (æœ€å¿«)
    L2_REDIS = "l2_redis"        # Redisç¼“å­˜ (å¿«)
    L3_FILE = "l3_file"          # æ–‡ä»¶ç¼“å­˜ (ä¸­)
    L4_MONGODB = "l4_mongodb"    # MongoDBç¼“å­˜ (æ…¢)


class CacheStrategy(Enum):
    """ç¼“å­˜ç­–ç•¥"""
    WRITE_THROUGH = "write_through"      # å†™å…¥æ—¶åŒæ—¶æ›´æ–°ç¼“å­˜
    WRITE_BACK = "write_back"            # å†™å›ç¼“å­˜
    WRITE_AROUND = "write_around"        # ç»•è¿‡ç¼“å­˜ç›´æ¥å†™å…¥
    REFRESH_AHEAD = "refresh_ahead"      # é¢„åˆ·æ–°


@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    key: str
    ttl: int  # ç§’
    level: CacheLevel
    strategy: CacheStrategy = CacheStrategy.WRITE_THROUGH
    enabled: bool = True
    tags: Set[str] = field(default_factory=set)
    warm_on_startup: bool = False
    invalidate_on: Set[str] = field(default_factory=set)  # è§¦å‘å¤±æ•ˆçš„äº‹ä»¶


@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    key: str
    hits: int = 0
    misses: int = 0
    evictions: int = 0
    size: int = 0
    last_access: Optional[datetime] = None
    created_at: datetime = field(default_factory=datetime.now)

    @property
    def hit_rate(self) -> float:
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0


class CacheManager:
    """
    ç»Ÿä¸€ç¼“å­˜ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. åˆ†å±‚ç¼“å­˜ç®¡ç†
    2. ç¼“å­˜é¢„çƒ­
    3. ç¼“å­˜å¤±æ•ˆç­–ç•¥
    4. ç¼“å­˜ç»Ÿè®¡å’Œç›‘æ§
    5. è‡ªåŠ¨é™çº§
    """

    # é¢„å®šä¹‰çš„ç¼“å­˜é…ç½®
    CACHE_CONFIGS: Dict[str, CacheConfig] = {
        # é…ç½®ç¼“å­˜
        "system_config": CacheConfig(
            key="system_config",
            ttl=300,  # 5åˆ†é’Ÿ
            level=CacheLevel.L1_MEMORY,
            tags={"config", "system"},
            warm_on_startup=True,
        ),

        # å¸‚åœºæŠ¥ä»·ç¼“å­˜
        "market_quotes": CacheConfig(
            key="market_quotes",
            ttl=10,  # 10ç§’ (å®æ—¶æ•°æ®)
            level=CacheLevel.L2_REDIS,
            tags={"market", "quotes"},
            invalidate_on={"market_close"},
        ),

        # è‚¡ç¥¨æ–°é—»ç¼“å­˜
        "stock_news": CacheConfig(
            key="stock_news",
            ttl=300,  # 5åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"news", "stock"},
        ),

        # å¸‚åœºæ–°é—»ç¼“å­˜
        "market_news": CacheConfig(
            key="market_news",
            ttl=600,  # 10åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"news", "market"},
        ),

        # AIåˆ†æç»“æœç¼“å­˜
        "ai_analysis": CacheConfig(
            key="ai_analysis",
            ttl=3600,  # 1å°æ—¶
            level=CacheLevel.L2_REDIS,
            tags={"analysis", "ai"},
        ),

        # è¶‹åŠ¿åˆ†æç¼“å­˜
        "trend_analysis": CacheConfig(
            key="trend_analysis",
            ttl=1800,  # 30åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"analysis", "trend"},
        ),

        # ç­›é€‰ç»“æœç¼“å­˜
        "screening_result": CacheConfig(
            key="screening_result",
            ttl=600,  # 10åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"screening"},
        ),

        # å†å²Kçº¿ç¼“å­˜
        "historical_klines": CacheConfig(
            key="historical_klines",
            ttl=86400,  # 24å°æ—¶
            level=CacheLevel.L3_FILE,
            tags={"data", "klines"},
        ),

        # è´¢åŠ¡æ•°æ®ç¼“å­˜
        "financials": CacheConfig(
            key="financials",
            ttl=43200,  # 12å°æ—¶
            level=CacheLevel.L3_FILE,
            tags={"data", "fundamentals"},
        ),

        # ç›‘æ§åˆ—è¡¨ç¼“å­˜
        "watchlist": CacheConfig(
            key="watchlist",
            ttl=60,  # 1åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"user", "watchlist"},
        ),

        # æ’è¡Œæ¦œç¼“å­˜
        "rankings": CacheConfig(
            key="rankings",
            ttl=300,  # 5åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"market", "rankings"},
        ),

        # çƒ­è¯ç¼“å­˜
        "hot_words": CacheConfig(
            key="hot_words",
            ttl=1800,  # 30åˆ†é’Ÿ
            level=CacheLevel.L2_REDIS,
            tags={"news", "analysis"},
        ),
    }

    def __init__(self):
        self._redis_service: Optional[RedisService] = None
        self._memory_cache: ConfigCache = ConfigCache(default_ttl=300)
        self._stats: Dict[str, CacheStats] = {}
        self._warm_tasks: List[Callable] = []
        self._initialized = False

        # åˆå§‹åŒ–ç»Ÿè®¡
        for key, config in self.CACHE_CONFIGS.items():
            self._stats[key] = CacheStats(key=key)

    async def initialize(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        if self._initialized:
            return

        try:
            self._redis_service = get_redis_service()
            logger.info("âœ… CacheManager initialized with Redis backend")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis not available, using memory-only cache: {e}")
            self._redis_service = None

        # æ³¨å†Œé¢„çƒ­ä»»åŠ¡
        self._register_warm_tasks()

        # æ‰§è¡Œç¼“å­˜é¢„çƒ­
        await self.warmup()

        self._initialized = True
        logger.info(f"âœ… CacheManager ready ({len(self.CACHE_CONFIGS)} cache configs)")

    def _register_warm_tasks(self):
        """æ³¨å†Œç¼“å­˜é¢„çƒ­ä»»åŠ¡"""
        # ç³»ç»Ÿé…ç½®é¢„çƒ­
        self._warm_tasks.append(self._warm_system_config)

    async def warmup(self):
        """ç¼“å­˜é¢„çƒ­"""
        logger.info("ğŸ”¥ Starting cache warmup...")

        for key, config in self.CACHE_CONFIGS.items():
            if config.warm_on_startup:
                try:
                    await self._warm_cache(key)
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to warm cache {key}: {e}")

        logger.info("âœ… Cache warmup complete")

    async def _warm_cache(self, key: str):
        """é¢„çƒ­å•ä¸ªç¼“å­˜"""
        # è¿™ä¸ªæ–¹æ³•éœ€è¦æ ¹æ®å…·ä½“ä¸šåŠ¡å®ç°
        logger.debug(f"ğŸ”¥ Warming cache: {key}")
        # TODO: å®ç°å…·ä½“çš„é¢„çƒ­é€»è¾‘

    async def _warm_system_config(self):
        """é¢„çƒ­ç³»ç»Ÿé…ç½®"""
        # TODO: åŠ è½½ç³»ç»Ÿé…ç½®åˆ°ç¼“å­˜
        pass

    def get_config(self, key: str) -> Optional[CacheConfig]:
        """è·å–ç¼“å­˜é…ç½®"""
        return self.CACHE_CONFIGS.get(key)

    def get_stats(self, key: str) -> Optional[CacheStats]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        return self._stats.get(key)

    def get_all_stats(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ç¼“å­˜ç»Ÿè®¡"""
        return {
            key: {
                "hits": stats.hits,
                "misses": stats.misses,
                "hit_rate": stats.hit_rate,
                "size": stats.size,
                "last_access": stats.last_access.isoformat() if stats.last_access else None,
            }
            for key, stats in self._stats.items()
        }

    async def get(self, key: str, default: Any = None) -> Optional[Any]:
        """
        è·å–ç¼“å­˜å€¼

        æ ¹æ®é…ç½®çš„ç¼“å­˜çº§åˆ«ï¼Œä»ç›¸åº”çš„å±‚çº§è·å–æ•°æ®
        """
        config = self.get_config(key)
        if not config or not config.enabled:
            return default

        stats = self._stats.get(key)
        if stats:
            stats.last_access = datetime.now()

        # æ ¹æ®ç¼“å­˜çº§åˆ«è·å–æ•°æ®
        if config.level == CacheLevel.L1_MEMORY:
            value = self._memory_cache.get(key)
            if value is not None:
                if stats:
                    stats.hits += 1
                return value
            if stats:
                stats.misses += 1
            return default

        elif config.level == CacheLevel.L2_REDIS:
            if self._redis_service:
                value = await self._redis_service.get_json(self._make_redis_key(key))
                if value is not None:
                    if stats:
                        stats.hits += 1
                    return value
                if stats:
                    stats.misses += 1
            return default

        # L3_FILE å’Œ L4_MONGODB æš‚ä¸å®ç°
        return default

    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """
        è®¾ç½®ç¼“å­˜å€¼

        æ ¹æ®é…ç½®çš„ç¼“å­˜çº§åˆ«å’Œç­–ç•¥ï¼Œè®¾ç½®ç¼“å­˜
        """
        config = self.get_config(key)
        if not config or not config.enabled:
            return False

        cache_ttl = ttl or config.ttl

        # æ ¹æ®ç¼“å­˜çº§åˆ«è®¾ç½®æ•°æ®
        if config.level == CacheLevel.L1_MEMORY:
            self._memory_cache.set(key, value, ttl=cache_ttl)
            stats = self._stats.get(key)
            if stats:
                stats.size += 1
            return True

        elif config.level == CacheLevel.L2_REDIS:
            if self._redis_service:
                await self._redis_service.set_json(
                    self._make_redis_key(key),
                    value,
                    ttl=cache_ttl
                )
                stats = self._stats.get(key)
                if stats:
                    stats.size += 1
                return True
            return False

        return False

    async def delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        config = self.get_config(key)
        if not config:
            return False

        # åˆ é™¤æ‰€æœ‰å±‚çº§çš„ç¼“å­˜
        if config.level == CacheLevel.L1_MEMORY:
            self._memory_cache.invalidate(key)

        elif config.level == CacheLevel.L2_REDIS:
            if self._redis_service:
                await self._redis_service.redis.delete(self._make_redis_key(key))

        stats = self._stats.get(key)
        if stats:
            stats.evictions += 1
            stats.size = max(0, stats.size - 1)

        return True

    async def invalidate_by_tag(self, tag: str) -> int:
        """æŒ‰æ ‡ç­¾å¤±æ•ˆç¼“å­˜"""
        count = 0
        for key, config in self.CACHE_CONFIGS.items():
            if tag in config.tags:
                await self.delete(key)
                count += 1
        logger.info(f"ğŸ—‘ï¸ Invalidated {count} caches with tag: {tag}")
        return count

    async def invalidate_by_event(self, event: str) -> int:
        """æŒ‰äº‹ä»¶å¤±æ•ˆç¼“å­˜"""
        count = 0
        for key, config in self.CACHE_CONFIGS.items():
            if event in config.invalidate_on:
                await self.delete(key)
                count += 1
        logger.info(f"ğŸ—‘ï¸ Invalidated {count} caches on event: {event}")
        return count

    def _make_redis_key(self, key: str) -> str:
        """ç”ŸæˆRedisé”®å"""
        return f"cache:{key}"

    @asynccontextmanager
    async def cached_context(self, key: str, ttl: Optional[int] = None):
        """
        ç¼“å­˜ä¸Šä¸‹æ–‡ç®¡ç†å™¨

        ä½¿ç”¨ç¤ºä¾‹:
            async with cache_manager.cached_context("my_key") as result:
                if result is None:
                    # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œè®¡ç®—
                    result = await expensive_operation()
                    await cache_manager.set("my_key", result, ttl)
                # ä½¿ç”¨ result
        """
        result = await self.get(key)
        yield result
        if result is not None:
            await self.set(key, result, ttl)


# å…¨å±€å•ä¾‹
_cache_manager: Optional[CacheManager] = None


def get_cache_manager() -> CacheManager:
    """è·å–ç¼“å­˜ç®¡ç†å™¨å®ä¾‹"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = CacheManager()
    return _cache_manager


async def init_cache_manager():
    """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
    manager = get_cache_manager()
    await manager.initialize()


def cached(
    cache_key: str,
    ttl: Optional[int] = None,
    level: Optional[CacheLevel] = None,
):
    """
    ç¼“å­˜è£…é¥°å™¨

    ä½¿ç”¨ç¤ºä¾‹:
        @cached("my_func", ttl=300)
        async def expensive_function(arg1, arg2):
            # ... è€—æ—¶æ“ä½œ
            return result
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            manager = get_cache_manager()

            # ç”Ÿæˆå®é™…çš„ç¼“å­˜é”®
            actual_key = f"{cache_key}:{args}:{kwargs}"

            # å°è¯•ä»ç¼“å­˜è·å–
            cached_value = await manager.get(actual_key)
            if cached_value is not None:
                return cached_value

            # ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œå‡½æ•°
            result = await func(*args, **kwargs)

            # å­˜å…¥ç¼“å­˜
            await manager.set(actual_key, result, ttl)

            return result

        return wrapper

    return decorator


class CacheAwareMixin:
    """ç¼“å­˜æ„ŸçŸ¥æ··å…¥ç±»"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._cache_manager = get_cache_manager()

    async def cache_get(self, key: str, default: Any = None) -> Optional[Any]:
        """è·å–ç¼“å­˜"""
        return await self._cache_manager.get(key, default)

    async def cache_set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """è®¾ç½®ç¼“å­˜"""
        return await self._cache_manager.set(key, value, ttl)

    async def cache_delete(self, key: str) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        return await self._cache_manager.delete(key)

    async def cache_invalidate_by_tag(self, tag: str) -> int:
        """æŒ‰æ ‡ç­¾å¤±æ•ˆç¼“å­˜"""
        return await self._cache_manager.invalidate_by_tag(tag)
