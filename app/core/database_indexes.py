"""
æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–è„šæœ¬

Phase 3-06: Database Query Optimization - Index Management

æä¾›æ•°æ®åº“ç´¢å¼•çš„åˆ›å»ºã€ç®¡ç†å’Œä¼˜åŒ–åŠŸèƒ½ï¼š
- è‡ªåŠ¨åˆ›å»ºç´¢å¼•
- ç´¢å¼•æ€§èƒ½åˆ†æ
- ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
- ç´¢å¼•ä¼˜åŒ–å»ºè®®
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Set, Tuple
from enum import Enum

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import ASCENDING, DESCENDING, TEXT
from pymongo.errors import OperationFailure

from .database import get_database

logger = logging.getLogger(__name__)


class IndexType(Enum):
    """ç´¢å¼•ç±»å‹"""
    SINGLE = "single"           # å•å­—æ®µç´¢å¼•
    COMPOUND = "compound"       # å¤åˆç´¢å¼•
    TEXT = "text"               # æ–‡æœ¬ç´¢å¼•
    GEOSPATIAL = "geospatial"   # åœ°ç†ç©ºé—´ç´¢å¼•
    HASHED = "hashed"           # å“ˆå¸Œç´¢å¼•
    UNIQUE = "unique"           # å”¯ä¸€ç´¢å¼•


@dataclass
class IndexSpec:
    """ç´¢å¼•è§„èŒƒ"""
    name: str
    collection: str
    keys: Dict[str, int]  # å­—æ®µåå’Œæ’åºæ–¹å‘ (1=ASC, -1=DESC)
    index_type: IndexType = IndexType.COMPOUND
    unique: bool = False
    sparse: bool = False
    background: bool = True
    expire_after_seconds: Optional[int] = None
    weights: Optional[Dict[str, int]] = None  # ç”¨äºæ–‡æœ¬ç´¢å¼•
    partial_filter: Optional[Dict[str, Any]] = None  # éƒ¨åˆ†ç´¢å¼•


@dataclass
class IndexStats:
    """ç´¢å¼•ç»Ÿè®¡"""
    name: str
    collection: str
    size: int = 0
    count: int = 0
    usage_count: int = 0
    last_used: Optional[datetime] = None
    created_at: Optional[datetime] = None


class DatabaseIndexManager:
    """
    æ•°æ®åº“ç´¢å¼•ç®¡ç†å™¨

    åŠŸèƒ½ï¼š
    1. ç®¡ç†æ‰€æœ‰é›†åˆçš„ç´¢å¼•
    2. åˆ›å»ºå’Œåˆ é™¤ç´¢å¼•
    3. åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ
    4. æä¾›ä¼˜åŒ–å»ºè®®
    """

    # é¢„å®šä¹‰çš„ç´¢å¼•è§„èŒƒ
    INDEX_SPECS: List[IndexSpec] = [
        # ========== è‚¡ç¥¨æ•°æ® ==========
        IndexSpec(
            name="stock_symbol_idx",
            collection="stocks",
            keys={"symbol": 1},
            index_type=IndexType.SINGLE,
            unique=True,
        ),
        IndexSpec(
            name="stock_code_market_idx",
            collection="stocks",
            keys={"code": 1, "market": 1},
            index_type=IndexType.COMPOUND,
            unique=True,
        ),

        # ========== Kçº¿æ•°æ® ==========
        IndexSpec(
            name="kline_symbol_period_date_idx",
            collection="klines",
            keys={"symbol": 1, "period": 1, "timestamp": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="kline_date_idx",
            collection="klines",
            keys={"timestamp": -1},
            index_type=IndexType.SINGLE,
        ),
        IndexSpec(
            name="kline_ttl_idx",
            collection="klines",
            keys={"created_at": 1},
            index_type=IndexType.SINGLE,
            expire_after_seconds=86400 * 30,  # 30å¤©
        ),

        # ========== æ–°é—»æ•°æ® ==========
        IndexSpec(
            name="news_symbol_date_idx",
            collection="news",
            keys={"symbols": 1, "published_at": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="news_date_idx",
            collection="news",
            keys={"published_at": -1},
            index_type=IndexType.SINGLE,
        ),
        IndexSpec(
            name="news_source_date_idx",
            collection="news",
            keys={"source": 1, "published_at": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="news_tags_idx",
            collection="news",
            keys={"tags": 1},
            index_type=IndexType.SINGLE,
        ),
        IndexSpec(
            name="news_text_idx",
            collection="news",
            keys={"title": "text", "content": "text"},
            index_type=IndexType.TEXT,
            weights={"title": 10, "content": 1},
        ),

        # ========== è´¢åŠ¡æ•°æ® ==========
        IndexSpec(
            name="financials_symbol_date_idx",
            collection="financials",
            keys={"symbol": 1, "report_date": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="financials_symbol_type_idx",
            collection="financials",
            keys={"symbol": 1, "report_type": 1},
            index_type=IndexType.COMPOUND,
        ),

        # ========== AIåˆ†æç»“æœ ==========
        IndexSpec(
            name="ai_analysis_symbol_type_idx",
            collection="ai_analysis",
            keys={"symbol": 1, "analysis_type": 1, "created_at": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="ai_analysis_created_idx",
            collection="ai_analysis",
            keys={"created_at": -1},
            index_type=IndexType.SINGLE,
        ),
        IndexSpec(
            name="ai_analysis_ttl_idx",
            collection="ai_analysis",
            keys={"created_at": 1},
            index_type=IndexType.SINGLE,
            expire_after_seconds=86400 * 7,  # 7å¤©
        ),

        # ========== è¶‹åŠ¿åˆ†æ ==========
        IndexSpec(
            name="trend_analysis_symbol_period_idx",
            collection="trend_analysis",
            keys={"symbol": 1, "period": 1, "updated_at": -1},
            index_type=IndexType.COMPOUND,
        ),

        # ========== ç­›é€‰ç»“æœ ==========
        IndexSpec(
            name="screening_key_idx",
            collection="screening_results",
            keys={"cache_key": 1},
            index_type=IndexType.SINGLE,
            unique=True,
            sparse=True,
        ),
        IndexSpec(
            name="screening_created_idx",
            collection="screening_results",
            keys={"created_at": 1},
            index_type=IndexType.SINGLE,
            expire_after_seconds=600,  # 10åˆ†é’Ÿ
        ),

        # ========== ç›‘æ§åˆ—è¡¨ ==========
        IndexSpec(
            name="watchlist_user_idx",
            collection="watchlists",
            keys={"user_id": 1, "updated_at": -1},
            index_type=IndexType.COMPOUND,
        ),

        # ========== çƒ­è¯ ==========
        IndexSpec(
            name="hot_words_date_idx",
            collection="hot_words",
            keys={"date": -1, "count": -1},
            index_type=IndexType.COMPOUND,
        ),

        # ========== åˆ†æä»»åŠ¡ ==========
        IndexSpec(
            name="tasks_status_idx",
            collection="analysis_tasks",
            keys={"status": 1, "created_at": -1},
            index_type=IndexType.COMPOUND,
        ),
        IndexSpec(
            name="tasks_user_idx",
            collection="analysis_tasks",
            keys={"user_id": 1, "created_at": -1},
            index_type=IndexType.COMPOUND,
        ),
    ]

    def __init__(self):
        self._db = None
        self._stats: Dict[str, IndexStats] = {}

    async def initialize(self):
        """åˆå§‹åŒ–ç´¢å¼•ç®¡ç†å™¨"""
        self._db = get_database()
        logger.info("âœ… DatabaseIndexManager initialized")

    async def create_all_indexes(self, force: bool = False) -> Dict[str, Any]:
        """
        åˆ›å»ºæ‰€æœ‰ç´¢å¼•

        Args:
            force: æ˜¯å¦å¼ºåˆ¶é‡å»ºå·²å­˜åœ¨çš„ç´¢å¼•

        Returns:
            åˆ›å»ºç»“æœç»Ÿè®¡
        """
        results = {
            "created": [],
            "existing": [],
            "failed": [],
        }

        logger.info("ğŸ”§ Starting index creation...")

        for spec in self.INDEX_SPECS:
            try:
                collection = self._db[spec.collection]
                existing_indexes = await collection.index_information()

                if spec.name in existing_indexes and not force:
                    results["existing"].append(spec.name)
                    logger.debug(f"â­ï¸  Index already exists: {spec.collection}.{spec.name}")
                    continue

                # æ„å»ºç´¢å¼•é€‰é¡¹
                index_options = {
                    "name": spec.name,
                    "background": spec.background,
                }

                if spec.unique:
                    index_options["unique"] = True
                if spec.sparse:
                    index_options["sparse"] = True
                if spec.expire_after_seconds:
                    index_options["expireAfterSeconds"] = spec.expire_after_seconds
                if spec.weights:
                    index_options["weights"] = spec.weights
                if spec.partial_filter:
                    index_options["partialFilterExpression"] = spec.partial_filter

                # åˆ›å»ºç´¢å¼•
                if spec.index_type == IndexType.TEXT:
                    await collection.create_index(
                        [(k, TEXT) for k in spec.keys.keys()],
                        **index_options
                    )
                else:
                    await collection.create_index(
                        list(spec.keys.items()),
                        **index_options
                    )

                results["created"].append(spec.name)
                logger.info(f"âœ… Created index: {spec.collection}.{spec.name}")

            except OperationFailure as e:
                results["failed"].append(spec.name)
                logger.error(f"âŒ Failed to create index {spec.collection}.{spec.name}: {e}")
            except Exception as e:
                results["failed"].append(spec.name)
                logger.error(f"âŒ Unexpected error creating index {spec.collection}.{spec.name}: {e}")

        logger.info(
            f"ğŸ”§ Index creation complete: "
            f"{len(results['created'])} created, "
            f"{len(results['existing'])} existing, "
            f"{len(results['failed'])} failed"
        )

        return results

    async def drop_index(self, collection: str, index_name: str) -> bool:
        """åˆ é™¤æŒ‡å®šç´¢å¼•"""
        try:
            coll = self._db[collection]
            await coll.drop_index(index_name)
            logger.info(f"ğŸ—‘ï¸  Dropped index: {collection}.{index_name}")
            return True
        except Exception as e:
            logger.error(f"âŒ Failed to drop index {collection}.{index_name}: {e}")
            return False

    async def get_collection_indexes(self, collection: str) -> List[Dict[str, Any]]:
        """è·å–é›†åˆçš„æ‰€æœ‰ç´¢å¼•"""
        try:
            coll = self._db[collection]
            indexes = await coll.index_information()
            return [
                {
                    "name": name,
                    "keys": spec.get("key", {}),
                    "unique": spec.get("unique", False),
                    "sparse": spec.get("sparse", False),
                    "ttl": spec.get("expireAfterSeconds"),
                }
                for name, spec in indexes.items()
            ]
        except Exception as e:
            logger.error(f"âŒ Failed to get indexes for {collection}: {e}")
            return []

    async def analyze_index_usage(self) -> Dict[str, Any]:
        """
        åˆ†æç´¢å¼•ä½¿ç”¨æƒ…å†µ

        Returns:
            ç´¢å¼•ä½¿ç”¨ç»Ÿè®¡
        """
        stats = {}

        for spec in self.INDEX_SPECS:
            try:
                coll = self._db[spec.collection]

                # è·å–ç´¢å¼•ä¿¡æ¯
                indexes = await coll.index_information()

                if spec.name not in indexes:
                    continue

                index_info = indexes[spec.name]

                # è·å–é›†åˆç»Ÿè®¡
                coll_stats = await self._db.command("collstats", spec.collection)

                stats[f"{spec.collection}.{spec.name}"] = {
                    "size": index_info.get("size", 0),
                    "collection_size": coll_stats.get("size", 0),
                    "document_count": coll_stats.get("count", 0),
                }

            except Exception as e:
                logger.warning(f"âš ï¸ Failed to analyze index {spec.collection}.{spec.name}: {e}")

        return stats

    async def get_optimization_suggestions(self) -> List[Dict[str, Any]]:
        """
        è·å–ç´¢å¼•ä¼˜åŒ–å»ºè®®

        Returns:
            ä¼˜åŒ–å»ºè®®åˆ—è¡¨
        """
        suggestions = []

        # æ£€æŸ¥ç¼ºå¤±çš„ç´¢å¼•
        for spec in self.INDEX_SPECS:
            try:
                coll = self._db[spec.collection]
                indexes = await coll.index_information()

                if spec.name not in indexes:
                    suggestions.append({
                        "type": "missing_index",
                        "priority": "high",
                        "collection": spec.collection,
                        "index_name": spec.name,
                        "message": f"Missing index {spec.name} on {spec.collection}",
                        "action": "create_index",
                    })

            except Exception as e:
                logger.warning(f"âš ï¸ Failed to check index {spec.collection}.{spec.name}: {e}")

        # æ£€æŸ¥æœªä½¿ç”¨çš„ç´¢å¼•
        # TODO: å®ç°åŸºäº $indexStats çš„æœªä½¿ç”¨ç´¢å¼•æ£€æµ‹

        # æ£€æŸ¥é‡å¤çš„ç´¢å¼•
        # TODO: å®ç°é‡å¤ç´¢å¼•æ£€æµ‹

        return suggestions

    async def get_query_performance(
        self,
        collection: str,
        filter: Dict[str, Any],
    ) -> Dict[str, Any]:
        """
        åˆ†ææŸ¥è¯¢æ€§èƒ½

        Args:
            collection: é›†åˆå
            filter: æŸ¥è¯¢æ¡ä»¶

        Returns:
            æŸ¥è¯¢æ€§èƒ½åˆ†æç»“æœ
        """
        try:
            coll = self._db[collection]

            # ä½¿ç”¨ explain åˆ†ææŸ¥è¯¢
            plan = await coll.find(filter).explain()

            return {
                "collection": collection,
                "filter": filter,
                "wins": plan.get("queryPlanner", {}).get("winningPlan", {}),
                "rejected_plans": plan.get("queryPlanner", {}).get("rejectedPlans", []),
                "execution_stats": plan.get("executionStats", {}),
                "docs_examined": plan.get("executionStats", {}).get("totalDocsExamined", 0),
                "keys_examined": plan.get("executionStats", {}).get("totalKeysExamined", 0),
                "execution_time_ms": plan.get("executionStats", {}).get("executionTimeMillis", 0),
            }

        except Exception as e:
            logger.error(f"âŒ Failed to analyze query performance: {e}")
            return {}

    async def verify_indexes(self) -> Dict[str, bool]:
        """
        éªŒè¯æ‰€æœ‰ç´¢å¼•æ˜¯å¦æ­£ç¡®åˆ›å»º

        Returns:
            ç´¢å¼•éªŒè¯ç»“æœ
        """
        results = {}

        for spec in self.INDEX_SPECS:
            try:
                coll = self._db[spec.collection]
                indexes = await coll.index_information()
                results[f"{spec.collection}.{spec.name}"] = spec.name in indexes
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to verify index {spec.collection}.{spec.name}: {e}")
                results[f"{spec.collection}.{spec.name}"] = False

        return results

    async def compact_collections(self) -> Dict[str, Any]:
        """
        å‹ç¼©é›†åˆä»¥å›æ”¶ç©ºé—´

        Returns:
            å‹ç¼©ç»“æœ
        """
        results = {
            "success": [],
            "failed": [],
        }

        # è·å–æ‰€æœ‰é›†åˆå
        collections = await self._db.list_collection_names()

        for coll_name in collections:
            try:
                await self._db.command("compact", coll_name)
                results["success"].append(coll_name)
                logger.info(f"âœ… Compacted collection: {coll_name}")
            except Exception as e:
                results["failed"].append(coll_name)
                logger.warning(f"âš ï¸ Failed to compact {coll_name}: {e}")

        return results


# å…¨å±€å•ä¾‹
_index_manager: Optional[DatabaseIndexManager] = None


def get_index_manager() -> DatabaseIndexManager:
    """è·å–ç´¢å¼•ç®¡ç†å™¨å®ä¾‹"""
    global _index_manager
    if _index_manager is None:
        _index_manager = DatabaseIndexManager()
    return _index_manager


async def init_database_indexes(force_rebuild: bool = False) -> Dict[str, Any]:
    """
    åˆå§‹åŒ–æ•°æ®åº“ç´¢å¼•

    Args:
        force_rebuild: æ˜¯å¦å¼ºåˆ¶é‡å»ºæ‰€æœ‰ç´¢å¼•

    Returns:
        åˆ›å»ºç»“æœ
    """
    manager = get_index_manager()
    await manager.initialize()
    return await manager.create_all_indexes(force=force_rebuild)


async def verify_database_indexes() -> Dict[str, bool]:
    """éªŒè¯æ•°æ®åº“ç´¢å¼•"""
    manager = get_index_manager()
    await manager.initialize()
    return await manager.verify_indexes()


async def get_index_optimization_suggestions() -> List[Dict[str, Any]]:
    """è·å–ç´¢å¼•ä¼˜åŒ–å»ºè®®"""
    manager = get_index_manager()
    await manager.initialize()
    return await manager.get_optimization_suggestions()
